{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "400ae3dd",
   "metadata": {},
   "source": [
    "# Notebook ETL de Comercio Regional\n",
    "Este cuaderno documenta el flujo completo de extracción, limpieza, transformación y carga para los datasets mensuales de ventas regionales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbe7fa8",
   "metadata": {},
   "source": [
    "## 1. Configurar entorno y bibliotecas\n",
    "Definimos variables de rutas y cargamos librerias clave para un flujo ETL robusto (pandas, numpy, janitor, great_expectations, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d531735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PosixPath('..'), PosixPath('../data/raw'), PosixPath('../data/processed'))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import janitor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "BASE_DIR = Path(\"..\")\n",
    "SRC_DIR = BASE_DIR / \"src\"\n",
    "if str(SRC_DIR.resolve()) not in sys.path:\n",
    "    sys.path.insert(0, str(SRC_DIR.resolve()))\n",
    "\n",
    "from comercio_regional.pipeline import RegionalSalesPipeline\n",
    "from comercio_regional.config import PipelineConfig\n",
    "\n",
    "DATA_DIR = BASE_DIR / \"data\"\n",
    "RAW_DIR = DATA_DIR / \"raw\"\n",
    "PROCESSED_DIR = DATA_DIR / \"processed\"\n",
    "\n",
    "os.environ.setdefault(\"COMERCIO_BASE_DIR\", str(BASE_DIR.resolve()))\n",
    "\n",
    "BASE_DIR, RAW_DIR, PROCESSED_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9e0326",
   "metadata": {},
   "source": [
    "## 2. Carga de datos crudos\n",
    "Utilizamos funciones reutilizables para leer archivos CSV y validar los tipos detectados durante la carga."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5bc40e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fecha                                  datetime64[ns]\n",
       "Compraventas, Venta regional, monto             int64\n",
       "region                                         object\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fecha</th>\n",
       "      <th>Compraventas, Venta regional, monto</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-08-01</td>\n",
       "      <td>685</td>\n",
       "      <td>araucania</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>713</td>\n",
       "      <td>araucania</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-06-01</td>\n",
       "      <td>685</td>\n",
       "      <td>araucania</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-05-01</td>\n",
       "      <td>721</td>\n",
       "      <td>araucania</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-04-01</td>\n",
       "      <td>755</td>\n",
       "      <td>araucania</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Fecha  Compraventas, Venta regional, monto     region\n",
       "0 2025-08-01                                  685  araucania\n",
       "1 2025-07-01                                  713  araucania\n",
       "2 2025-06-01                                  685  araucania\n",
       "3 2025-05-01                                  721  araucania\n",
       "4 2025-04-01                                  755  araucania"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_raw_sources(raw_dir: Path) -> pd.DataFrame:\n",
    "    frames = []\n",
    "    for csv_path in sorted(raw_dir.glob(\"dataset_*.csv\")):\n",
    "        frame = pd.read_csv(\n",
    "            csv_path,\n",
    "            parse_dates=[\"Fecha\"],\n",
    "            dayfirst=True,\n",
    "            thousands=\".\",\n",
    "            decimal=\",\",\n",
    "        )\n",
    "        frame[\"region\"] = csv_path.stem.replace(\"dataset_\", \"\")\n",
    "        frames.append(frame)\n",
    "    if not frames:\n",
    "        raise FileNotFoundError(\"No se encontraron datasets en data/raw\")\n",
    "    combined = pd.concat(frames, ignore_index=True)\n",
    "    inferred_types = combined.dtypes\n",
    "    display(inferred_types)\n",
    "    return combined\n",
    "\n",
    "raw_df = read_raw_sources(RAW_DIR)\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52bf9d3",
   "metadata": {},
   "source": [
    "## 3. Perfilado exploratorio basico\n",
    "Calculamos estadisticos descriptivos, graficas y exploramos outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ccd73c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fecha</th>\n",
       "      <th>Compraventas, Venta regional, monto</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>460</td>\n",
       "      <td>460.000000</td>\n",
       "      <td>460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>araucania</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2021-10-16 01:33:54.782608640</td>\n",
       "      <td>4506.113043</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2018-01-01 00:00:00</td>\n",
       "      <td>165.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2019-11-23 12:00:00</td>\n",
       "      <td>418.500000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2021-10-16 12:00:00</td>\n",
       "      <td>900.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2023-09-08 12:00:00</td>\n",
       "      <td>1575.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2025-08-01 00:00:00</td>\n",
       "      <td>30743.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>7780.362839</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Fecha  Compraventas, Venta regional, monto  \\\n",
       "count                             460                           460.000000   \n",
       "unique                            NaN                                  NaN   \n",
       "top                               NaN                                  NaN   \n",
       "freq                              NaN                                  NaN   \n",
       "mean    2021-10-16 01:33:54.782608640                          4506.113043   \n",
       "min               2018-01-01 00:00:00                           165.000000   \n",
       "25%               2019-11-23 12:00:00                           418.500000   \n",
       "50%               2021-10-16 12:00:00                           900.000000   \n",
       "75%               2023-09-08 12:00:00                          1575.000000   \n",
       "max               2025-08-01 00:00:00                         30743.000000   \n",
       "std                               NaN                          7780.362839   \n",
       "\n",
       "           region  \n",
       "count         460  \n",
       "unique          5  \n",
       "top     araucania  \n",
       "freq           92  \n",
       "mean          NaN  \n",
       "min           NaN  \n",
       "25%           NaN  \n",
       "50%           NaN  \n",
       "75%           NaN  \n",
       "max           NaN  \n",
       "std           NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rango intercuartil: (np.float64(-1316.25), np.float64(3309.75))\n"
     ]
    }
   ],
   "source": [
    "summary = raw_df.describe(include=\"all\")\n",
    "display(summary)\n",
    "\n",
    "monto_outliers = raw_df[\"Compraventas, Venta regional, monto\"].astype(float)\n",
    "q1, q3 = np.nanpercentile(monto_outliers, [25, 75])\n",
    "iqr = q3 - q1\n",
    "lower_bound = q1 - 1.5 * iqr\n",
    "upper_bound = q3 + 1.5 * iqr\n",
    "print(\"Rango intercuartil:\", (lower_bound, upper_bound))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900e98b3",
   "metadata": {},
   "source": [
    "## 4. Limpieza y estandarizacion de columnas\n",
    "Renombramos columnas al formato `snake_case`, removemos espacios y resolvemos duplicados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cbd069c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fecha</th>\n",
       "      <th>monto</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-08-01</td>\n",
       "      <td>685</td>\n",
       "      <td>araucania</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>713</td>\n",
       "      <td>araucania</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-06-01</td>\n",
       "      <td>685</td>\n",
       "      <td>araucania</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-05-01</td>\n",
       "      <td>721</td>\n",
       "      <td>araucania</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-04-01</td>\n",
       "      <td>755</td>\n",
       "      <td>araucania</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fecha  monto     region\n",
       "0 2025-08-01    685  araucania\n",
       "1 2025-07-01    713  araucania\n",
       "2 2025-06-01    685  araucania\n",
       "3 2025-05-01    721  araucania\n",
       "4 2025-04-01    755  araucania"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df = (\n",
    "    raw_df.copy()\n",
    "    .rename(columns={\"Fecha\": \"fecha\", \"Compraventas, Venta regional, monto\": \"monto\"})\n",
    "    .clean_names()\n",
    ")\n",
    "clean_df = clean_df.drop_duplicates()\n",
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d14c85e",
   "metadata": {},
   "source": [
    "## 5. Tratamiento de valores faltantes\n",
    "Identificamos columnas con `NaN` y aplicamos imputacion condicional documentando el impacto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e15862b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fecha     0\n",
       "monto     0\n",
       "region    0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'monto': 'median', 'region': 'constant: sin_region'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_summary = clean_df.isna().sum()\n",
    "display(missing_summary)\n",
    "\n",
    "imputed_df = clean_df.copy()\n",
    "imputed_df[\"monto\"] = imputed_df[\"monto\"].fillna(imputed_df[\"monto\"].median())\n",
    "imputed_df[\"region\"] = imputed_df[\"region\"].fillna(\"sin_region\")\n",
    "\n",
    "imputation_log = {\n",
    "    \"monto\": \"median\",\n",
    "    \"region\": \"constant: sin_region\",\n",
    "}\n",
    "imputation_log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1ae4b4",
   "metadata": {},
   "source": [
    "## 6. Normalizacion y codificacion de variables\n",
    "Estandarizamos unidades y codificamos las variables categoricas para analisis y modelado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2802f13b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fecha</th>\n",
       "      <th>monto</th>\n",
       "      <th>region</th>\n",
       "      <th>monto_normalizado</th>\n",
       "      <th>monto_escalado</th>\n",
       "      <th>region_araucania</th>\n",
       "      <th>region_biobio</th>\n",
       "      <th>region_los-lagos</th>\n",
       "      <th>region_los-rios</th>\n",
       "      <th>region_santiago</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-08-01</td>\n",
       "      <td>685</td>\n",
       "      <td>araucania</td>\n",
       "      <td>685.0</td>\n",
       "      <td>-0.491657</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>713</td>\n",
       "      <td>araucania</td>\n",
       "      <td>713.0</td>\n",
       "      <td>-0.488055</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-06-01</td>\n",
       "      <td>685</td>\n",
       "      <td>araucania</td>\n",
       "      <td>685.0</td>\n",
       "      <td>-0.491657</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-05-01</td>\n",
       "      <td>721</td>\n",
       "      <td>araucania</td>\n",
       "      <td>721.0</td>\n",
       "      <td>-0.487025</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-04-01</td>\n",
       "      <td>755</td>\n",
       "      <td>araucania</td>\n",
       "      <td>755.0</td>\n",
       "      <td>-0.482651</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fecha  monto     region  monto_normalizado  monto_escalado  \\\n",
       "0 2025-08-01    685  araucania              685.0       -0.491657   \n",
       "1 2025-07-01    713  araucania              713.0       -0.488055   \n",
       "2 2025-06-01    685  araucania              685.0       -0.491657   \n",
       "3 2025-05-01    721  araucania              721.0       -0.487025   \n",
       "4 2025-04-01    755  araucania              755.0       -0.482651   \n",
       "\n",
       "   region_araucania  region_biobio  region_los-lagos  region_los-rios  \\\n",
       "0               1.0            0.0               0.0              0.0   \n",
       "1               1.0            0.0               0.0              0.0   \n",
       "2               1.0            0.0               0.0              0.0   \n",
       "3               1.0            0.0               0.0              0.0   \n",
       "4               1.0            0.0               0.0              0.0   \n",
       "\n",
       "   region_santiago  \n",
       "0              0.0  \n",
       "1              0.0  \n",
       "2              0.0  \n",
       "3              0.0  \n",
       "4              0.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "feature_df = imputed_df.assign(\n",
    "    monto_normalizado=lambda df: df[\"monto\"].astype(float)\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "feature_df[\"monto_escalado\"] = scaler.fit_transform(feature_df[[\"monto_normalizado\"]])\n",
    "\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "region_encoded = encoder.fit_transform(feature_df[[\"region\"]])\n",
    "region_cols = [f\"region_{cat}\" for cat in encoder.categories_[0]]\n",
    "encoded_region_df = pd.DataFrame(region_encoded, columns=region_cols)\n",
    "feature_df = pd.concat([feature_df.reset_index(drop=True), encoded_region_df], axis=1)\n",
    "feature_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bbd1b4",
   "metadata": {},
   "source": [
    "## 7. Validacion de calidad de datos\n",
    "Definimos expectativas de integridad, unicidad y rangos mediante comprobaciones programaticas inspiradas en Great Expectations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d343ce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'monto_no_nulos': np.True_,\n",
       " 'monto_no_negativo': np.True_,\n",
       " 'region_no_nula': np.True_,\n",
       " 'fechas_ordenadas': True}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def validate_dataset(df: pd.DataFrame) -> dict[str, bool]:\n",
    "    checks = {\n",
    "        \"monto_no_nulos\": df[\"monto_normalizado\"].notna().all(),\n",
    "        \"monto_no_negativo\": (df[\"monto_normalizado\"] >= 0).all(),\n",
    "        \"region_no_nula\": df[\"region\"].notna().all(),\n",
    "        \"fechas_ordenadas\": df.sort_values(\"fecha\")[\"fecha\"].is_monotonic_increasing,\n",
    "    }\n",
    "    return checks\n",
    "\n",
    "validation_results = validate_dataset(feature_df)\n",
    "validation_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cc2144",
   "metadata": {},
   "source": [
    "## 8. Transformacion final y union de tablas\n",
    "Construimos el pipeline final combinando datasets enriquecidos y agregamos metricas mensuales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ea8ad9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>periodo</th>\n",
       "      <th>anio</th>\n",
       "      <th>mes</th>\n",
       "      <th>trimestre</th>\n",
       "      <th>monto_total</th>\n",
       "      <th>monto_promedio</th>\n",
       "      <th>observaciones</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Araucania</td>\n",
       "      <td>2018-01</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>2018Q1</td>\n",
       "      <td>359</td>\n",
       "      <td>359.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Araucania</td>\n",
       "      <td>2018-02</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>2018Q1</td>\n",
       "      <td>404</td>\n",
       "      <td>404.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Araucania</td>\n",
       "      <td>2018-03</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>2018Q1</td>\n",
       "      <td>410</td>\n",
       "      <td>410.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Araucania</td>\n",
       "      <td>2018-04</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>2018Q2</td>\n",
       "      <td>402</td>\n",
       "      <td>402.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Araucania</td>\n",
       "      <td>2018-05</td>\n",
       "      <td>2018</td>\n",
       "      <td>5</td>\n",
       "      <td>2018Q2</td>\n",
       "      <td>394</td>\n",
       "      <td>394.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      region  periodo  anio  mes trimestre  monto_total  monto_promedio  \\\n",
       "0  Araucania  2018-01  2018    1    2018Q1          359           359.0   \n",
       "1  Araucania  2018-02  2018    2    2018Q1          404           404.0   \n",
       "2  Araucania  2018-03  2018    3    2018Q1          410           410.0   \n",
       "3  Araucania  2018-04  2018    4    2018Q2          402           402.0   \n",
       "4  Araucania  2018-05  2018    5    2018Q2          394           394.0   \n",
       "\n",
       "   observaciones  \n",
       "0              1  \n",
       "1              1  \n",
       "2              1  \n",
       "3              1  \n",
       "4              1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_config = PipelineConfig.default(base_dir=BASE_DIR)\n",
    "pipeline = RegionalSalesPipeline(pipeline_config)\n",
    "\n",
    "data_for_pipeline = imputed_df[[\"fecha\", \"monto\", \"region\"]].copy()\n",
    "\n",
    "processed_df = data_for_pipeline\n",
    "for step in pipeline.steps():\n",
    "    processed_df = step(processed_df)\n",
    "\n",
    "processed_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a5da15",
   "metadata": {},
   "source": [
    "## 9. Carga de datos procesados\n",
    "Exportamos los resultados a Parquet y registramos metadatos clave de versionado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fea7da23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rows': 460,\n",
       " 'columns': ['region',\n",
       "  'periodo',\n",
       "  'anio',\n",
       "  'mes',\n",
       "  'trimestre',\n",
       "  'monto_total',\n",
       "  'monto_promedio',\n",
       "  'observaciones'],\n",
       " 'output_path': '../data/processed/ventas_regionales_notebook.csv'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_path = PROCESSED_DIR / \"ventas_regionales_notebook.csv\"\n",
    "PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "processed_df.to_csv(output_path, index=False)\n",
    "\n",
    "metadata = {\n",
    "    \"rows\": len(processed_df),\n",
    "    \"columns\": list(processed_df.columns),\n",
    "    \"output_path\": str(output_path),\n",
    "}\n",
    "metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3101ef7e",
   "metadata": {},
   "source": [
    "## 10. Pruebas automatizadas del flujo ETL\n",
    "Mostramos como integrar `pytest` para validar las funciones criticas del pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "755c1ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "def test_pipeline_runs(tmp_path):\n",
      "    config = PipelineConfig.default(base_dir=Path('..'))\n",
      "    pipeline = RegionalSalesPipeline(config)\n",
      "    pipeline.run()\n",
      "    assert pipeline.output_path.exists()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "\n",
    "pytest_example = textwrap.dedent(\n",
    "    \"\"\"\n",
    "    def test_pipeline_runs(tmp_path):\n",
    "        config = PipelineConfig.default(base_dir=Path('..'))\n",
    "        pipeline = RegionalSalesPipeline(config)\n",
    "        pipeline.run()\n",
    "        assert pipeline.output_path.exists()\n",
    "    \"\"\"\n",
    ")\n",
    "print(pytest_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed552c8",
   "metadata": {},
   "source": [
    "## Visualización interactiva con estilo The Economist\n",
    "En esta sección exploramos la serie limpia `ventas_regionales_notebook.csv` mediante gráficos con estética inspirada en The Economist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9348b488",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from plotly.colors import qualitative\n",
    "\n",
    "processed_path = PROCESSED_DIR / \"ventas_regionales_notebook.csv\"\n",
    "viz_df = pd.read_csv(processed_path, parse_dates=[\"periodo\"])\n",
    "viz_df = viz_df.sort_values([\"periodo\", \"region\"])\n",
    "viz_df[\"region\"] = viz_df[\"region\"].str.replace(\"-\", \" \").str.title()\n",
    "\n",
    "economist_font = dict(family=\"Georgia, serif\", color=\"#1e293b\")\n",
    "palette = qualitative.T10"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
